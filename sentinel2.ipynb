{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sentinel(BASE_URL, key_json, project_id, start, end, tile, cloud=100.):\n",
    "    \"\"\"\n",
    "    Queries the Google Cloud BigQuery database to retrieve Sentinel-2 imagery metadata based on specified criteria.\n",
    "    \n",
    "    Parameters:\n",
    "    - BASE_URL (str): The base URL used to construct download URLs.\n",
    "    - key_json (str): Path to the JSON key file for Google Cloud service account.\n",
    "    - project_id (str): Google Cloud project ID.\n",
    "    - start (datetime): Start date for filtering Sentinel-2 scenes.\n",
    "    - end (datetime): End date for filtering Sentinel-2 scenes.\n",
    "    - tile (str): MGRS tile identifier.\n",
    "    - cloud (float, optional): Maximum allowed cloud cover percentage. Default is 100%.\n",
    "\n",
    "    Returns:\n",
    "    - good_scenes (list): A list of URLs for Sentinel-2 scenes with cloud cover below the specified threshold.\n",
    "    \"\"\"\n",
    "    credentials = service_account.Credentials.from_service_account_file(key_json)\n",
    "    client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "    query = client.query(\"\"\"\n",
    "                SELECT * FROM `bigquery-public-data.cloud_storage_geo_index.sentinel_2_index` \n",
    "                    WHERE mgrs_tile IN (\"{t}\") \n",
    "                    AND DATE(sensing_time) BETWEEN DATE(\"{s}\") AND DATE(\"{e}\")\n",
    "                \"\"\".format(t=tile, s=start, e=end))\n",
    "    results = query.result()\n",
    "    df = results.to_dataframe()\n",
    "    good_scenes = []\n",
    "    for i, row in df.iterrows():\n",
    "        print (row['product_id'], '; cloud cover:', row['cloud_cover'])\n",
    "        if float(row['cloud_cover']) <= cloud:\n",
    "            good_scenes.append(row['base_url'].replace('gs://', BASE_URL))\n",
    "    return good_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, dst_name):\n",
    "    \"\"\"\n",
    "    Downloads a file from a given URL and saves it to the specified destination.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): The URL of the file to be downloaded.\n",
    "    - dst_name (str): The local destination path where the file will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = requests.get(url, stream=True)\n",
    "        with open(dst_name, 'wb') as out_file:\n",
    "            for chunk in data.iter_content(chunk_size=100 * 100):\n",
    "                out_file.write(chunk)\n",
    "    except:\n",
    "        print ('\\t ... {f} FAILED!'.format(f=url.split('/')[-1]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_safe_dirs(scene, outpath):\n",
    "    \"\"\"\n",
    "    Creates a directory structure for a Sentinel-2 scene and downloads the manifest file.\n",
    "\n",
    "    Parameters:\n",
    "    - scene (str): URL of the Sentinel-2 scene.\n",
    "    - outpath (str): Local path where the scene directory will be created.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples containing download links and local paths for files in the scene.\n",
    "    \"\"\"\n",
    "    scene_name = os.path.basename(scene)\n",
    "    scene_path = os.path.join(outpath, scene_name)\n",
    "    manifest = os.path.join(scene_path, 'manifest.safe')\n",
    "    manifest_url = scene + '/manifest.safe'\n",
    "    if os.path.exists(manifest):\n",
    "        os.remove(manifest)\n",
    "    download_file(manifest_url, manifest)\n",
    "    with open(manifest, 'r') as f:\n",
    "        manifest_lines = f.read().split()\n",
    "    download_links = []\n",
    "    load_this = False\n",
    "    for line in manifest_lines:\n",
    "        if(len(manifest_lines)>1600):\n",
    "            if 'href' in line:\n",
    "                online_path = line[7:line.find('><')]\n",
    "                tile = scene_name.split('_')[-2]\n",
    "                if online_path.startswith('/GRANULE/'):\n",
    "                    if '_' + tile + '_' in online_path:\n",
    "                        load_this = True\n",
    "                else:\n",
    "                    load_this = True\n",
    "                if load_this:\n",
    "                    local_path = os.path.join(scene_path, *online_path.split('/')[1:])\n",
    "                    online_path = scene + online_path\n",
    "                    download_links.append((online_path, local_path))\n",
    "        else:\n",
    "            if 'href' in line:\n",
    "                online_path = line[7:line.find('><') - 2]\n",
    "                tile = scene_name.split('_')[-2]\n",
    "                if online_path.startswith('/GRANULE/'):\n",
    "                    if '_' + tile + '_' in online_path:\n",
    "                        load_this = True\n",
    "                else:\n",
    "                    load_this = True\n",
    "                if load_this:\n",
    "                    local_path = os.path.join(scene_path, *online_path.split('/')[1:])\n",
    "                    online_path = scene + online_path\n",
    "                    download_links.append((online_path, local_path))\n",
    "        load_this = False\n",
    "    for extra_dir in ('AUX_DATA', 'HTML','rep_info'):\n",
    "        if not os.path.exists(os.path.join(scene_path, extra_dir)):\n",
    "            os.makedirs(os.path.join(scene_path, extra_dir))\n",
    "        if(extra_dir == 'rep_info'):\n",
    "            url = scene +'/rep_info/S2_User_Product_Level-1C_Metadata.xsd'\n",
    "            urllib.request.urlretrieve(url, os.path.join(scene_path, extra_dir)+'/S2_User_Product_Level-1C_Metadata.xsd')\n",
    "\n",
    "    return download_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_sentinel(scene, dst):\n",
    "    \"\"\"\n",
    "    Downloads files associated with a Sentinel-2 scene to a specified destination.\n",
    "\n",
    "    Parameters:\n",
    "    - scene (str): URL of the Sentinel-2 scene.\n",
    "    - dst (str): Local directory where scene files will be downloaded.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    scene_name = scene.split('/')[-1]\n",
    "    scene_path = os.path.join(dst, scene_name)\n",
    "    if not os.path.exists(scene_path):\n",
    "        os.mkdir(scene_path)\n",
    "    print ('Downloading scene {s} ...'.format(s=scene_name))\n",
    "    download_links = sorted(make_safe_dirs(scene, dst))\n",
    "    for l in download_links:\n",
    "        if not os.path.exists(os.path.dirname(l[1])):\n",
    "            os.makedirs(os.path.dirname(l[1]))\n",
    "        if os.path.exists(l[1]):\n",
    "            os.remove(l[1])\n",
    "        if l[1].endswith('.jp2'):\n",
    "            print ('\\t ... *{b}'.format(b=l[1].split('_')[-1]))\n",
    "        if download_file(l[0], l[1]) is False:\n",
    "            print ('\\t ... {f} failed to download! Download for this scene is cancelled here!'.format(f=l[0]))\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook can be used in three ways presented bellow:\n",
    "- The first one is with the user interpreting with the environment variables, changing the saving destination folder, the cloud percentage etc. \n",
    "- The second is reading a .csv file with all necessary information like tile, product tile, image_date etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL1C_20191012T075851_N0208_R035_T37QDD_20191012T092728 ; cloud cover: 7.2512\n",
      "Downloading scene S2A_MSIL1C_20191012T075851_N0208_R035_T37QDD_20191012T092728.SAFE ...\n",
      "\t ... *B01.jp2\n",
      "\t ... *B02.jp2\n",
      "\t ... *B03.jp2\n",
      "\t ... *B04.jp2\n",
      "\t ... *B05.jp2\n",
      "\t ... *B06.jp2\n",
      "\t ... *B07.jp2\n",
      "\t ... *B08.jp2\n",
      "\t ... *B09.jp2\n",
      "\t ... *B10.jp2\n",
      "\t ... *B11.jp2\n",
      "\t ... *B12.jp2\n",
      "\t ... *B8A.jp2\n",
      "\t ... *TCI.jp2\n",
      "\t ... *PVI.jp2\n"
     ]
    }
   ],
   "source": [
    "# Download one product\n",
    "BASE_URL = 'http://storage.googleapis.com/'\n",
    "key_json = \".../path-to-key.json\"\n",
    "project_id = '-'.join(key_json.split('/',-1)[-1].split('.',-1)[0].split('-',-1)[:-1])\n",
    "outdir = '.../path-to-output'\n",
    "tile = '37QDD'\n",
    "cloud = 20\n",
    "\n",
    "start = datetime.strptime('2019/10/12',\"%Y/%m/%d\")\n",
    "end = start\n",
    "\n",
    "scene_list = query_sentinel(BASE_URL, key_json, project_id, start, end, tile, cloud)\n",
    "for s in scene_list:\n",
    "    download_sentinel(s, outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download multiple products\n",
    "csv_path = \".../path-to-csv.csv\"\n",
    "df = pd.read_csv(csv_path, index_col=0, header=0,low_memory=False)\n",
    "df = df.sort_values(by=['Lat'])\n",
    "df.index = range(df.shape[0])\n",
    "df = df.iloc[34:,:]\n",
    "df = df[df.Product_title!='0']\n",
    "df.index = range(df.shape[0])\n",
    "for k in range(df.shape[0]):\n",
    "    tile = df.tile.iloc[k]\n",
    "    cloud = 20\n",
    "    strip = df.Image_date.iloc[k].split(\"/\",2)\n",
    "    start = datetime.strptime(strip[2]+str('/')+strip[0]+str('/')+strip[1],\"%Y/%m/%d\")\n",
    "    end = datetime.strptime(strip[2]+str('/')+strip[0]+str('/')+strip[1],\"%Y/%m/%d\")\n",
    "    scene_list = query_sentinel(BASE_URL, key_json, project_id, start, end, tile, cloud)\n",
    "    for s in scene_list:\n",
    "        download_sentinel(s, outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
