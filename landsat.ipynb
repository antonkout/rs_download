{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fresh-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db930a",
   "metadata": {},
   "source": [
    "<b>Landsat</b> is an ongoing mission of Earth observation satellites developed under a joint program of the USGS and NASA. The Landsat mission provides the longest continuous space-based record of Earth's land, dating back to 1972 and the Landsat 1 satellite. Starting with Landsat 4, each of the satellites imaged the Earth's surface at a 30-meter resolution about once every two weeks using multispectral and thermal instruments.\n",
    "<br>\n",
    "<br>This <b>Cloud Storage</b> dataset includes the Collection 1 USGS archive from Landsat 4, 5, 7, and 8:<os>\n",
    "    <li>Landsat 4: 1982 - 1993</li>\n",
    "    <li>Landsat 5: 1984 - 2013</li>\n",
    "    <li>Landsat 7: 1999 - 2021</li>\n",
    "    <li>Landsat 8: 2013 - 2021</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "satellite-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, dst_name):\n",
    "    \"\"\"\n",
    "    Downloads a file from a specified URL and saves it to the local destination.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): URL of the file to be downloaded.\n",
    "    - dst_name (str): Local path where the file will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = requests.get(url, stream=True)\n",
    "        with open(dst_name, 'wb') as out_file:\n",
    "            for chunk in data.iter_content(chunk_size=100 * 100):\n",
    "                out_file.write(chunk)\n",
    "    except:\n",
    "        print ('\\t ... {f} FAILED!'.format(f=url.split('/')[-1]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "peripheral-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_landsat(BASE_URL, key_json, project_id, start, end, spacecraft_id, cloud, wrs_row, wrs_path):\n",
    "    \"\"\"\n",
    "    Queries the Landsat dataset in BigQuery to find scenes matching specified criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - BASE_URL (str): Base URL for accessing Google Cloud Storage.\n",
    "    - key_json (str): Path to the JSON file containing service account credentials.\n",
    "    - project_id (str): Google Cloud project ID.\n",
    "    - start (str): Start date for filtering scenes in the format \"YYYY-MM-DD\".\n",
    "    - end (str): End date for filtering scenes in the format \"YYYY-MM-DD\".\n",
    "    - spacecraft_id (str): Landsat spacecraft identifier (e.g., \"LANDSAT_8\").\n",
    "    - cloud (float): Maximum cloud cover percentage allowed for scenes.\n",
    "    - wrs_row (int): WRS row number for filtering scenes.\n",
    "    - wrs_path (int): WRS path number for filtering scenes.\n",
    "\n",
    "    Returns:\n",
    "    - good_scenes (list): List of URLs for scenes that meet the specified criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    credentials = service_account.Credentials.from_service_account_file(key_json)\n",
    "    client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "    query = client.query(\"\"\"\n",
    "                SELECT * FROM `bigquery-public-data.cloud_storage_geo_index.landsat_index` \n",
    "                    WHERE wrs_path = ({t}) AND wrs_row = ({r})\n",
    "                    AND spacecraft_id = (\"{i}\")\n",
    "                    AND DATE(sensing_time) BETWEEN DATE(\"{s}\") AND DATE(\"{e}\")\n",
    "                \"\"\".format(t=wrs_path, r=wrs_row, i=spacecraft_id, s=start, e=end))\n",
    "    results = query.result()\n",
    "    df = results.to_dataframe()\n",
    "    good_scenes = []\n",
    "    for i, row in df.iterrows():\n",
    "        if float(row['cloud_cover']) <= cloud:\n",
    "            print (row['product_id'], '; cloud cover:', row['cloud_cover'])\n",
    "            good_scenes.append(row['base_url'].replace('gs://', BASE_URL))\n",
    "    return good_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "level-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_safe_dirs(scene, outpath): \n",
    "    \"\"\"\n",
    "    Downloads and organizes Landsat scene files into a directory structure.\n",
    "\n",
    "    Parameters:\n",
    "    - scene (str): URL of the Landsat scene.\n",
    "    - outpath (str): Output directory where the scene files will be organized.\n",
    "\n",
    "    Returns:\n",
    "    - download_links (list): List of tuples containing online and local paths for downloaded files.\n",
    "    \"\"\"\n",
    "    scene_name = os.path.basename(scene)\n",
    "    scene_path = os.path.join(outpath, scene_name)\n",
    "    manifest = os.path.join(scene_path, scene_name+'_MTL.txt')\n",
    "    manifest_url = scene + '/'+scene_name+'_MTL.txt'\n",
    "    if os.path.exists(manifest):\n",
    "        os.remove(manifest)\n",
    "    download_file(manifest_url, manifest)\n",
    "    \n",
    "    manifest_ang = os.path.join(scene_path, scene_name+'_ANG.txt')\n",
    "    manifest_ang_url = scene + '/'+scene_name+'_ANG.txt'\n",
    "    if os.path.exists(manifest_ang):\n",
    "        os.remove(manifest_ang)\n",
    "    download_file(manifest_ang_url, manifest_ang)\n",
    "    \n",
    "    with open(manifest, 'r') as f:\n",
    "        manifest_lines = f.read().split(\"\\n\")\n",
    "    download_links = []\n",
    "    data = requests.get(manifest_url, stream=True)\n",
    "    with open(manifest, 'wb') as out_file:\n",
    "        for chunk in data.iter_content(chunk_size=100 * 100):\n",
    "            out_file.write(chunk)\n",
    "    bands = ['    FILE_NAME_BAND_1 ','    FILE_NAME_BAND_2 ','    FILE_NAME_BAND_3 ','    FILE_NAME_BAND_4 ',\n",
    "            '    FILE_NAME_BAND_5 ','    FILE_NAME_BAND_6 ','    FILE_NAME_BAND_7 ','    FILE_NAME_BAND_8 ',\n",
    "            '    FILE_NAME_BAND_9 ','    FILE_NAME_BAND_10 ','    FILE_NAME_BAND_11 ', '    FILE_NAME_BAND_QUALITY ']\n",
    "    for line in manifest_lines:\n",
    "        for band in bands:\n",
    "            if band in line:\n",
    "                local_path = scene_path+'/'+line[line.find('\"')+1:-1]\n",
    "                online_path = scene +'/'+line[line.find('\"')+1:-1]\n",
    "                download_links.append((online_path, local_path))\n",
    "    return download_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "55c8f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_landsat(scene, dst, outpath):   \n",
    "    \"\"\"\n",
    "    Downloads Landsat scene files and organizes them into a directory structure.\n",
    "\n",
    "    Parameters:\n",
    "    - scene (str): URL of the Landsat scene.\n",
    "    - dst (str): Destination directory for the downloaded scene files.\n",
    "    - outpath (str): Output directory where the scene files will be organized.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    scene_name = os.path.basename(scene)\n",
    "    scene_path = os.path.join(outpath, scene_name)\n",
    "    if not os.path.exists(scene_path):\n",
    "        os.mkdir(scene_path)        \n",
    "    print ('Downloading scene {s} ...'.format(s=scene_name))\n",
    "    download_links = make_safe_dirs(scene, dst)\n",
    "    \n",
    "    for l in download_links:\n",
    "        if l[1].endswith('.TIF'):\n",
    "            print ('\\t ... *{b}'.format(b=l[1].split('_')[-1]))\n",
    "        if download_file(l[0], l[1]) is False:\n",
    "            print ('\\t ... {f} failed to download! Download for this scene is cancelled here!'.format(f=l[0]))\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bfbb68b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC08_L1GT_233122_20180120_20180206_01_T2 ; cloud cover: 0.0\n",
      "Downloading scene LC08_L1GT_233122_20180120_20180206_01_T2 ...\n",
      "\t ... *B1.TIF\n",
      "\t ... *B2.TIF\n",
      "\t ... *B3.TIF\n",
      "\t ... *B4.TIF\n",
      "\t ... *B5.TIF\n",
      "\t ... *B6.TIF\n",
      "\t ... *B7.TIF\n",
      "\t ... *B8.TIF\n",
      "\t ... *B9.TIF\n",
      "\t ... *B10.TIF\n",
      "\t ... *B11.TIF\n",
      "\t ... *BQA.TIF\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'http://storage.googleapis.com/'\n",
    "key_json = \".../path-to-key.json\"\n",
    "project_id = '-'.join(key_json.split('/',-1)[-1].split('.',-1)[0].split('-',-1)[:-1])\n",
    "start =  datetime.strptime('2018/01/18',\"%Y/%m/%d\") \n",
    "end =  datetime.strptime('2018/05/18',\"%Y/%m/%d\")\n",
    "cloud = 20\n",
    "wrs_row = 122\n",
    "wrs_path = 233\n",
    "spacecraft_id = 'LANDSAT_8'\n",
    "outdir = \".../path-to-output\" #desired output folder\n",
    "\n",
    "scene_list = query_landsat(BASE_URL, key_json, project_id, start, end, spacecraft_id, cloud, wrs_row, wrs_path)\n",
    "\n",
    "for s in scene_list:\n",
    "    download_landsat(s, outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
